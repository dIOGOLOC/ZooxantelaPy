{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d40e58e-efc2-4947-b808-455c3a239acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from matplotlib.dates import YearLocator, MonthLocator, DayLocator, HourLocator, MinuteLocator, SecondLocator, DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import obspy as op\n",
    "from obspy import read,read_inventory, UTCDateTime, Stream, Trace\n",
    "from obspy.clients.fdsn.client import Client\n",
    "from obspy.signal.rotate import rotate_ne_rt\n",
    "from obspy.geodetics import gps2dist_azimuth,kilometers2degrees\n",
    "from obspy.taup import TauPyModel\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from scipy.signal import spectrogram, detrend, resample,savgol_filter,decimate,hilbert\n",
    "from scipy.stats import circmean, circstd\n",
    "\n",
    "import pyarrow.feather as feather\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,HuberRegressor,TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00e400d2-d641-4abb-8f26-6ec9b323bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# Configuration file\n",
    "# ==================\n",
    "\n",
    "# Folders input\n",
    "\n",
    "EVENT_DIR = '/medata03/SEISCOMP_DATA/'\n",
    "\n",
    "XML_DIR = '/home/sysop/dados_posdoc/PROJETO_RSIS/XML/'\n",
    "\n",
    "# Folders output\n",
    "\n",
    "ORIENTATION_OUTPUT = '/home/sysop/dados_posdoc/PROJETO_RSIS/ORIENTATION_OUTPUT/'\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "# Stations and OBSs information\n",
    "\n",
    "#STATION_LST = ['VAS01','DUB01','CAM01','MAN01','ALF01','RIB01','GUA01','CMC01','GDU01','ANA01','TER01','MAJ01']\n",
    "STATION_LST = ['NAN01']\n",
    "PERIOD_BANDS = [0.02,0.5]\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "# create figures?\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "# Input parameters\n",
    "\n",
    "FIRSTDAY = '2014-01-01'\n",
    "LASTDAY = '2016-12-31'\n",
    "\n",
    "# default parameters to define the signal and noise windows used to estimate the SNR:\n",
    "# - the signal window is defined according to time after Rayleigh-wave arrival:\n",
    "\n",
    "TIME_WINDOW = 30\n",
    "\n",
    "# Rayleigh-wave time windows start\n",
    "TIME_START_P_REGIONAL = 3\n",
    "\n",
    "# Rayleigh-wave time windows final\n",
    "TIME_FINAL_P_REGIONAL = 12\n",
    "\n",
    "# min magnitude\n",
    "minmagnitude = 6\n",
    "\n",
    "# distance (MIN & MAX)\n",
    "GCARC_MIN = 5\n",
    "GCARC_MAX = 100\n",
    "\n",
    "# -------------------------------\n",
    "# Mappoing parameters\n",
    "\n",
    "LLCRNRLON_LARGE = -50\n",
    "URCRNRLON_LARGE = -38\n",
    "LLCRNRLAT_LARGE = -30\n",
    "URCRNRLAT_LARGE = -12\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "# Constants and parameters\n",
    "\n",
    "ONEDAY = datetime.timedelta(days=1)\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "# MULTIPROCESSING\n",
    "\n",
    "num_processes = 20\n",
    "\n",
    "# =================\n",
    "# Filtering by date\n",
    "# =================\n",
    "\n",
    "fday = UTCDateTime(FIRSTDAY)\n",
    "lday = UTCDateTime(LASTDAY)\n",
    "INTERVAL_PERIOD = [UTCDateTime(x.astype(str)) for x in np.arange(fday.datetime,lday.datetime+ONEDAY,ONEDAY)]\n",
    "INTERVAL_PERIOD_DATE = [str(x.year)+'.'+\"%03d\" % x.julday for x in INTERVAL_PERIOD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48373d9-8612-453e-8541-b524a99126fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========\n",
    "# Functions\n",
    "# =========\n",
    "\n",
    "def rms(x):\n",
    "    \"\"\"\n",
    "    Function to calculate root-mean-square of array\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : :class:`~numpy.ndarray`\n",
    "        Input array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rms : float\n",
    "        Root-Mean-Square value of `x`\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "\n",
    "def energy(x):\n",
    "    \"\"\"\n",
    "    Function to calculate energy of array\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : :class:`~numpy.ndarray`\n",
    "        Input array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    energy : float\n",
    "        Square value of `x`\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sum(x**2)\n",
    "    \n",
    "# --------------------------------------------------------------------------\n",
    "def Braunmiller_algorithm(tr1,tr2,trZ,ang,dphi):\n",
    "    \n",
    "    '''\n",
    "    The P-wave particle motion in an isotropic, homogeneous layered medium is in the direction of the seismic ray connecting\n",
    "    source and receiver along a great circle path. The horizontal\n",
    "    projection of the path from sensor to source defines the radial\n",
    "    direction and its angle with respect to true north is the back\n",
    "    azimuth. The P-wave energy in this medium is confined to the\n",
    "    vertical and radial seismogram components and zero on the\n",
    "    transverse component. We use this principle to estimate the\n",
    "    back azimuth. \n",
    "    \n",
    "    The sensor 'misorientation angle' is the difference\n",
    "    between true and empirically estimated back azimuth with\n",
    "    positive values for clockwise sensor misorientation.\n",
    "\n",
    "    == Quality criteria for automatic processing ==\n",
    "    For selecting reliable back azimuths, we implemented three quality criteria\n",
    "     - (1) overall signal strength;\n",
    "     - (2) similarity of vertical and radial components; and\n",
    "     - (3) low transverse-to-radial energy ratio.\n",
    "     - (4) low radial-to-vertical energy ratio.\n",
    "     \n",
    "    In addition, we required a minimum epicenter distance to minimize potential \n",
    "    systematic earthquake mislocation effects on back azimuths.\n",
    "    '''\n",
    "            \n",
    "    # Criterias\n",
    "       \n",
    "    signal_strength = np.zeros(len(ang))\n",
    "    similarity_ZR = np.zeros(len(ang))\n",
    "    energy_ratio_TR = np.zeros(len(ang))\n",
    "    energy_ratio_RZ = np.zeros(len(ang))\n",
    "    \n",
    "    # Search through azimuths from 0 to 180 deg and find best-fit azimuth                    \n",
    "    for k, an in enumerate(ang):\n",
    "        R, T = rotate_ne_rt(tr1, tr2, an)\n",
    "        \n",
    "        # Cross-correlation coefficient between vertical and radial component\n",
    "        similarity_ZR[k] = np.corrcoef(trZ,R)[0, 1]\n",
    "        \n",
    "        # Measure of the transverse to radial ratio\n",
    "        energy_ratio_TR[k] = 1. - energy(T)/energy(R)\n",
    "        \n",
    "        # Measure of the radial to vertical ratio\n",
    "        energy_ratio_RZ[k] = 1. - energy(R)/energy(trZ)\n",
    "        \n",
    "        signal_strength[k] = energy(T)\n",
    "\n",
    "    # Normalizing data\n",
    "    signal_strength = (signal_strength - np.min(signal_strength)) / (np.max(signal_strength) - np.min(signal_strength)) \n",
    "    energy_ratio_TR = (energy_ratio_TR - np.min(energy_ratio_TR)) / (np.max(energy_ratio_TR) - np.min(energy_ratio_TR)) \n",
    "    energy_ratio_RZ = (energy_ratio_RZ - np.min(energy_ratio_RZ)) / (np.max(energy_ratio_RZ) - np.min(energy_ratio_RZ)) \n",
    "    similarity_ZR = (similarity_ZR - np.min(similarity_ZR)) / (np.max(similarity_ZR) - np.min(similarity_ZR)) \n",
    "                    \n",
    "    return similarity_ZR,energy_ratio_TR,energy_ratio_RZ,signal_strength\n",
    "\n",
    "#-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5816da9d-0a59-47f2-913b-920bfea570e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Downloading events\n",
      "==================\n",
      "\n",
      "\n",
      "471 Event(s) in Catalog:\n",
      "2016-12-29T22:30:19.300000Z |  -9.028, +118.664 | 6.3  Mww\n",
      "2016-12-25T14:22:27.030000Z | -43.405,  -73.940 | 7.6  Mww\n",
      "...\n",
      "2014-01-13T04:01:04.530000Z | +18.992,  -66.868 | 6.3  MW\n",
      "2014-01-01T16:03:29.770000Z | -13.877, +167.272 | 6.5  MW\n",
      "To see all events call 'print(CatalogObject.__str__(print_all=True))'\n"
     ]
    }
   ],
   "source": [
    "# ============\n",
    "# Main program\n",
    "# ============\n",
    "print('==================')\n",
    "print('Downloading events')\n",
    "print('==================')\n",
    "print('\\n')\n",
    "\n",
    "client = Client('IRIS')\n",
    "\n",
    "cat = client.get_events(starttime=fday, endtime=lday, minmagnitude=minmagnitude)\n",
    "print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c7b533b-87e8-4340-8c5b-0e559f84ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_MIN = 10 #db\n",
    "CCVR_MIN = 0.7\n",
    "TRR_MIN = 0.7\n",
    "RVR_MIN = 0.2\n",
    "\n",
    "def calculate_orientation(sta):\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Retrieving events waveforms\n",
    "    # ---------------------------\n",
    "    \n",
    "    for event in tqdm(cat, total=len(cat),desc=sta+' orientation'):\n",
    "        # ------------------------------\n",
    "        # Check if the event is eligible\n",
    "\n",
    "        depth_event = event.origins[-1].depth/1000\n",
    "        event_time = event.origins[-1].time\n",
    "        event_name = event.origins[-1].time.strftime('%Y.%j.%H.%M.%S')\n",
    "\n",
    "        year = event.origins[-1].time.strftime('%Y')\n",
    "        julian_day = event.origins[-1].time.strftime('%j')\n",
    "\n",
    "        network = 'ON'\n",
    "        station = sta    \n",
    "                   \n",
    "        # ---------------\n",
    "        # Import XML file\n",
    "                        \n",
    "        xml_file = glob.glob(XML_DIR+network+'.'+sta+'*')[0]\n",
    "        station_xml = op.read_inventory(xml_file)\n",
    "                            \n",
    "        # Epicentral distance:\n",
    "            \n",
    "        sta_lon = station_xml[-1][-1][-1].longitude\n",
    "        sta_lat = station_xml[-1][-1][-1].latitude\n",
    "            \n",
    "        ev_lat = event.origins[-1].latitude\n",
    "        ev_lon = event.origins[-1].longitude\n",
    "            \n",
    "        dist_pair,az_pair,baz_pair = gps2dist_azimuth(ev_lat, ev_lon,sta_lat, sta_lon)\n",
    "        gcarc_pair = kilometers2degrees(dist_pair/1000)\n",
    "        baz_pair_round = round(baz_pair)\n",
    "        gcarc_pair_round = round(gcarc_pair)\n",
    "        dist_pair_round = round(dist_pair)  \n",
    "\n",
    "        # Taup: theoretical travel times \n",
    "        model = TauPyModel(model=\"iasp91\")\n",
    "        arrivals = model.get_travel_times(source_depth_in_km=depth_event,distance_in_degree=gcarc_pair)\n",
    "        \n",
    "        # Event time + P arrival time\n",
    "        event_time = event_time+arrivals[0].time\n",
    "        \n",
    "        if gcarc_pair > GCARC_MIN and gcarc_pair < GCARC_MAX:\n",
    "            # ----------------------------\n",
    "            # Check if feather file exists\n",
    "            \n",
    "            output_FEATHER_FILES_ORIENTATION = ORIENTATION_OUTPUT+'FEATHER_FILES/'+sta+'/'\n",
    "            \n",
    "            file_feather_name = output_FEATHER_FILES_ORIENTATION+sta+'_'+event_name+'_orientation_data.feather'\n",
    "    \n",
    "            station_pwd = glob.glob(EVENT_DIR+year+'/'+network+'/'+station+'/*')\n",
    "    \n",
    "            if os.path.isfile(file_feather_name):\n",
    "                pass\n",
    "        \n",
    "            else:\n",
    "                # -------------------------------\n",
    "                # Check if components file exists\n",
    "                        \n",
    "                if (len([i for i in station_pwd if 'HHE.D' in i or 'HH2.D' in i]) > 0 and\n",
    "                    len([i for i in station_pwd if 'HHN.D' in i or 'HH1.D' in i]) > 0 and\n",
    "                    len([i for i in station_pwd if 'HHZ.D' in i]) > 0):\n",
    "    \n",
    "                    if (len(glob.glob([i for i in station_pwd if 'HHE.D' in i or 'HH2.D' in i][0]+'/*'+year+'.'+julian_day)) > 0 and\n",
    "                        len(glob.glob([i for i in station_pwd if 'HHN.D' in i or 'HH1.D' in i][0]+'/*'+year+'.'+julian_day)) > 0 and\n",
    "                        len(glob.glob([i for i in station_pwd if 'HHZ.D' in i][0]+'/*'+year+'.'+julian_day)) > 0):\n",
    "                    \n",
    "                        try:\n",
    "                        \n",
    "                            file_HHE = glob.glob([i for i in station_pwd if 'HHE.D' in i or 'HH2.D' in i][0]+'/*'+year+'.'+julian_day)[0]\n",
    "                            file_HHN = glob.glob([i for i in station_pwd if 'HHN.D' in i or 'HH1.D' in i][0]+'/*'+year+'.'+julian_day)[0]\n",
    "                            file_HHZ = glob.glob([i for i in station_pwd if 'HHZ.D' in i][0]+'/*'+year+'.'+julian_day)[0]\n",
    "        \n",
    "                            # --------\n",
    "                            # Data HHE\n",
    "                            \n",
    "                            tr2_data_file = op.read(file_HHE)\n",
    "                            tr2_data_file.trim(event_time-TIME_WINDOW,event_time+TIME_WINDOW)\n",
    "                            tr2_data_file.taper(type='hann',max_percentage=0.1)\n",
    "                            tr2_data_file.filter('bandpass',freqmin=PERIOD_BANDS[0],freqmax=PERIOD_BANDS[1],zerophase=True, corners=4)\n",
    "                            tr2_data_filtered = tr2_data_file[0].data\n",
    "                \n",
    "                            # --------\n",
    "                            # Data HHN\n",
    "                \n",
    "                            tr1_data_file = op.read(file_HHN)\n",
    "                            tr1_data_file.trim(event_time-TIME_WINDOW,event_time+TIME_WINDOW)\n",
    "                            tr1_data_file.taper(type='hann',max_percentage=0.1)\n",
    "                            tr1_data_file.filter('bandpass',freqmin=PERIOD_BANDS[0],freqmax=PERIOD_BANDS[1],zerophase=True, corners=4)\n",
    "                            tr1_data_filtered = tr1_data_file[0].data\n",
    "                            \n",
    "                            # --------\n",
    "                            # Data HHZ\n",
    "                            \n",
    "                            trZ_data_file = op.read(file_HHZ)\n",
    "                            trZ_data_file.trim(event_time-TIME_WINDOW,event_time+TIME_WINDOW)\n",
    "                            trZ_data_file.taper(type='hann',max_percentage=0.1)\n",
    "                            trZ_data_file.filter('bandpass',freqmin=PERIOD_BANDS[0],freqmax=PERIOD_BANDS[1],zerophase=True, corners=4)\n",
    "                            trZ_data_filtered = trZ_data_file[0].data\n",
    "                            trZ_time = trZ_data_file[0].times()-TIME_WINDOW       \n",
    "                            \n",
    "                            # -------------------------------------------------------------------------------------------------------------------------------\n",
    "                            # Signal and noise windows\n",
    "    \n",
    "                            signal_window = (trZ_time >= -TIME_START_P_REGIONAL) & (trZ_time <= TIME_FINAL_P_REGIONAL)\n",
    "                            noise_window = (trZ_time >= -(TIME_START_P_REGIONAL+TIME_FINAL_P_REGIONAL)) & (trZ_time <= -TIME_START_P_REGIONAL)\n",
    "                            \n",
    "                            noise = trZ_data_filtered[noise_window]\n",
    "                            trZ_noise_time = trZ_time[noise_window]\n",
    "    \n",
    "                            tr2 = tr2_data_filtered[signal_window]\n",
    "                            tr1 = tr1_data_filtered[signal_window]\n",
    "                            trZ = trZ_data_filtered[signal_window]\n",
    "                            trZ_signal_time = trZ_time[signal_window]\n",
    "    \n",
    "                            # -------------------------------------------------------------------------------------------------------------------------------\n",
    "                            # Calculate and store SNR as attribute\n",
    "                            \n",
    "                            SNR = round(10.*np.log10(rms(trZ)**2/rms(noise)**2),1)\n",
    "                                 \n",
    "                            # -------------------------------------------------------------------------------------------------------------------------------\n",
    "                            # Search Space of BAZ\n",
    "                        \n",
    "                            dphi = 0.1\n",
    "                            ang = np.arange(0., 360., dphi)\n",
    "                            \n",
    "                            # -------------------------------------------------------------------------------------------------------------------------------\n",
    "                            # Calculating criterias\n",
    "                                            \n",
    "                            SZR,ERTR,ERRZ,SS = Braunmiller_algorithm(tr1,tr2,trZ,ang,dphi)\n",
    "                                           \n",
    "                            # Find best index\n",
    "                            cost_function = (\n",
    "                                                SS +  # Minimizing\n",
    "                                                (1 - SZR) +  # Maximizing similarity (equal to minimizing (1 - similarity))\n",
    "                                                ERTR +  # Minimizing\n",
    "                                                ERRZ  # Minimizing \n",
    "                                            )\n",
    "                        \n",
    "                            best_index = np.argmin(cost_function)\n",
    "                            \n",
    "                            # Get azimuth and correct for angles above 360\n",
    "                            phi = round(ang[best_index])\n",
    "                            orient = round(baz_pair - ang[best_index])\n",
    "                            \n",
    "                            # Get argument of maximum coherence:\n",
    "                            SZR_max = SZR[best_index]\n",
    "                            ERTR_max = ERTR[best_index]\n",
    "                            ERRZ_max = ERRZ[best_index]\n",
    "                            SS_max = SS[best_index]\n",
    "\n",
    "                            # ----------------------------------------------------------------------------------------------------\n",
    "                            \n",
    "                            if VERBOSE == True:\n",
    "                \n",
    "                                # --------------------\n",
    "                                # figure \n",
    "                                fig = plt.figure(figsize=(30, 10),constrained_layout=True)\n",
    "                                fig.suptitle('Evento: '+event_name+'(Δ: '+str(gcarc_pair_round)+'° | M: '+str(event.magnitudes[-1].mag)+' '+event.magnitudes[-1].magnitude_type+' | D: '+str(round(depth_event))+' km) \\n BAZ: '+str(baz_pair_round)+'° | PHI: '+str(phi)+'° | orient: '+str(orient)+'° | SNR: '+str(SNR)+' dB',fontsize=20)\n",
    "\n",
    "                                # creating grid\n",
    "                                gs = fig.add_gridspec(1, 2,width_ratios=[3,1])\n",
    "\n",
    "                                gs0 = gs[0].subgridspec(3, 1)\n",
    "                                gs1 = gs[1].subgridspec(4, 1)\n",
    "                                \n",
    "                                # Rotating components\n",
    "                                new_R, new_T = rotate_ne_rt(tr1_data_filtered, tr2_data_filtered, phi)\n",
    "\n",
    "                                # Transversal data\n",
    "                                ax1 = fig.add_subplot(gs0[0, 0])\n",
    "                                ax1.plot(trZ_time,new_T,'-k',lw=2)\n",
    "                                ax1.plot(trZ_signal_time,tr2,c='gray',ls='--',lw=0.5)\n",
    "                                ax1.annotate('Transversal', (0.9, 0.85),xycoords='axes fraction',fontsize=15, va='center',bbox=dict(boxstyle=\"round\", fc=\"white\"))\n",
    "                                ax1.set_xlim(-TIME_WINDOW,TIME_WINDOW)\n",
    "                                ax1.tick_params(axis=\"x\", labelbottom=False)\n",
    "                                ax1.axvline(x=-TIME_START_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "                                ax1.axvline(x=TIME_FINAL_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "\n",
    "                                # Radial data\n",
    "                                ax2 = fig.add_subplot(gs0[1, 0], sharex=ax1, sharey=ax1)\n",
    "                                ax2.plot(trZ_time,new_R,'-k')\n",
    "                                ax2.plot(trZ_signal_time,tr1,c='gray',ls='--',lw=0.5)\n",
    "                                ax2.annotate('Radial', (0.9, 0.85),xycoords='axes fraction',fontsize=15, va='center',bbox=dict(boxstyle=\"round\", fc=\"white\"))\n",
    "                                ax2.tick_params(axis=\"x\", labelbottom=False)\n",
    "                                ax2.axvline(x=-TIME_START_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "                                ax2.axvline(x=TIME_FINAL_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "\n",
    "                                # Vertical data and noise and signal window\n",
    "                                ax3 = fig.add_subplot(gs0[2, 0], sharex=ax1, sharey=ax1)\n",
    "                                ax3.plot(trZ_time,trZ_data_filtered,'-k')\n",
    "                                ax3.plot(trZ_noise_time,noise,'--b')\n",
    "                                ax3.plot(trZ_signal_time,trZ,'--r')\n",
    "                                ax3.annotate('Vertical', (0.9, 0.85),xycoords='axes fraction',fontsize=15, va='center',bbox=dict(boxstyle=\"round\", fc=\"white\"))\n",
    "                                ax3.set_xlabel('Timelag (s)',fontsize=15)\n",
    "                                ax3.axvline(x=-TIME_START_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "                                ax3.axvline(x=TIME_FINAL_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "\n",
    "                                # Transversal signal strength\n",
    "                                ax4 = fig.add_subplot(gs1[0, 0])\n",
    "                                ax4.plot(ang,SS,'.k')\n",
    "                                ax4.plot(phi,SS_max,'*r',ms=10)\n",
    "                                ax4.set_ylim(0,1)\n",
    "                                ax4.tick_params(axis=\"x\", labelbottom=False)\n",
    "                                ax4.set_title('Transversal signal strength',fontsize=15)\n",
    "                                \n",
    "                                # Similarity between vertical and radial\n",
    "                                ax5 = fig.add_subplot(gs1[1, 0], sharex=ax4)\n",
    "                                ax5.plot(ang,SZR,'.k')\n",
    "                                ax5.plot(phi,SZR_max,'*r',ms=10)\n",
    "                                ax5.set_ylim(0,1)\n",
    "                                ax5.set_xlim(0,360)\n",
    "                                ax5.tick_params(axis=\"x\", labelbottom=False)\n",
    "                                ax5.set_title('Similarity between vertical and radial',fontsize=15)\n",
    "\n",
    "                                # Transverse-to-Radial Energy Ratio\n",
    "                                ax6 = fig.add_subplot(gs1[2, 0], sharex=ax5)\n",
    "                                ax6.plot(ang,ERTR,'.k')\n",
    "                                ax6.plot(phi,ERTR_max,'*r',ms=10)\n",
    "                                ax6.tick_params(axis=\"x\", labelbottom=False)\n",
    "                                ax6.set_title('Transverse-to-Radial Energy Ratio',fontsize=15)\n",
    "                                                                \n",
    "                                # Radial-to-Vertical Energy Ratio\n",
    "                                ax7 = fig.add_subplot(gs1[3, 0], sharex=ax6)\n",
    "                                ax7.plot(ang,ERRZ,'.k')\n",
    "                                ax7.plot(phi,ERRZ_max,'*r',ms=10)\n",
    "                                ax7.set_title('Radial-to-Vertical Energy Ratio',fontsize=15)\n",
    "                                ax7.set_xlabel('Orientation Angle (deg)',fontsize=15)\n",
    "\n",
    "                                # --------------------------\n",
    "                                # Adding global location map\n",
    "\n",
    "                                ax_map = plt.axes([0.0, 0.82, 0.15, 0.15], projection=ccrs.Orthographic(central_latitude=sta_lat,central_longitude=sta_lon))\n",
    "                                ax_map.set_global()\n",
    "\n",
    "                                # ---------------------\n",
    "                                # Adding background map \n",
    "\n",
    "                                ax_map.add_feature(cfeature.LAND)\n",
    "                                ax_map.add_feature(cfeature.OCEAN)\n",
    "                                ax_map.add_feature(cfeature.COASTLINE)\n",
    "                            \n",
    "                                ax_map.scatter(ev_lon,ev_lat,color=\"y\",marker='*',s=200,ec='k',transform=ccrs.PlateCarree())\n",
    "                                ax_map.scatter(sta_lon,sta_lat,color=\"r\",marker='^',s=50,transform=ccrs.PlateCarree())\n",
    "                                ax_map.plot([sta_lon, ev_lon], [sta_lat, ev_lat], c='gray',ls='-',lw=2, transform=ccrs.Geodetic())\n",
    "        \n",
    "                                if (SZR_max >= CCVR_MIN) & (SNR >= SNR_MIN) & (ERTR_max >= TRR_MIN) & (ERRZ_max <= RVR_MIN):\n",
    "                                    label = 'good'\n",
    "                                    \n",
    "                                    # ----------------------------------------------------------------------------------------------------\n",
    "                                    # Creating a Pandas DataFrame:\n",
    "                                    column_info = [sta,event_name,dist_pair,gcarc_pair,baz_pair,SS_max,SZR_max,ERTR_max,ERRZ_max,SNR,phi,orient,label]\n",
    "                                    columns_header = ['station','event','distance','gcarc','baz','signal_strength','similarity_vertical_radial','energy_transverse_radial','energy_radial_vertical','SNR','phi','orient','quality']\n",
    "                                    orient_rayleigh_df = pd.DataFrame(column_info, index=columns_header).T\n",
    "                        \n",
    "                                    # ----------------------------------------------------------------------------------------------------\n",
    "                                    # Convert from pandas to Arrow and saving in feather formart file\n",
    "                                    os.makedirs(output_FEATHER_FILES_ORIENTATION,exist_ok=True)\n",
    "                                    feather.write_feather(orient_rayleigh_df, file_feather_name)\n",
    "                                else:\n",
    "                                    label = 'bad'\n",
    "                                    # ----------------------------------------------------------------------------------------------------\n",
    "                                    # Creating a Pandas DataFrame:\n",
    "                                    column_info = [sta,event_name,dist_pair,gcarc_pair,baz_pair,SS_max,SZR_max,ERTR_max,ERRZ_max,SNR,phi,orient,label]\n",
    "                                    columns_header = ['station','event','distance','gcarc','baz','signal_strength','similarity_vertical_radial','energy_transverse_radial','energy_radial_vertical','SNR','phi','orient','quality']\n",
    "                                    orient_rayleigh_df = pd.DataFrame(column_info, index=columns_header).T\n",
    "                        \n",
    "                                    # ----------------------------------------------------------------------------------------------------\n",
    "                                    # Convert from pandas to Arrow and saving in feather formart file\n",
    "                                    os.makedirs(output_FEATHER_FILES_ORIENTATION,exist_ok=True)\n",
    "                                    feather.write_feather(orient_rayleigh_df, file_feather_name)\n",
    "                                    \n",
    "                                output_figure_ORIENTATION = ORIENTATION_OUTPUT+'ORIENTATION_FIGURES/EARTHQUAKES/'+sta+'/'\n",
    "                                os.makedirs(output_figure_ORIENTATION,exist_ok=True)\n",
    "                                fig.savefig(output_figure_ORIENTATION+'ORIENTATION_'+sta+'_'+event_name+'_'+label+'.png',dpi=300)\n",
    "                                plt.close()\n",
    "                        except:\n",
    "                            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7aaff42-f461-40c1-90ff-78c6b83e6f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NAN01 orientation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 471/471 [06:54<00:00,  1.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [06:54<00:00, 414.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- 6.92 execution time (min) ---\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "with Pool(processes=20) as p:\n",
    "    max_ = len(STATION_LST)\n",
    "    with tqdm(total=max_) as pbar:\n",
    "        for result in p.imap_unordered(calculate_orientation,STATION_LST):\n",
    "            pbar.update()\n",
    "\n",
    "print('\\n')\n",
    "print(\"--- %.2f execution time (min) ---\" % ((time.time() - start_time)/60))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd4b1c-b2ea-43d5-a92f-e126670f080d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
