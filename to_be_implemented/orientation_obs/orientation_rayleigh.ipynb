{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40e58e-efc2-4947-b808-455c3a239acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from matplotlib.dates import YearLocator, MonthLocator, DayLocator, HourLocator, MinuteLocator, SecondLocator, DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import obspy as op\n",
    "from obspy import read,read_inventory, UTCDateTime, Stream, Trace\n",
    "from obspy.clients.fdsn.client import Client\n",
    "from obspy.signal.rotate import rotate_ne_rt\n",
    "from obspy.geodetics import gps2dist_azimuth,kilometers2degrees\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from scipy.signal import spectrogram, detrend, resample,savgol_filter,decimate,hilbert\n",
    "\n",
    "import pyarrow.feather as feather\n",
    "\n",
    "import datetime\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,HuberRegressor,TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e400d2-d641-4abb-8f26-6ec9b323bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# Configuration file\n",
    "# ==================\n",
    "\n",
    "# Folders input\n",
    "\n",
    "EVENT_DIR = '/medata01/SEISCOMP_DATA/'\n",
    "\n",
    "XML_DIR = '/home/sysop/dados_posdoc/PROJETO_RSIS/XML/'\n",
    "\n",
    "# Folders output\n",
    "\n",
    "ORIENTATION_OUTPUT = '/home/sysop/dados_posdoc/PROJETO_RSIS/ORIENTATION_OUTPUT/'\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "# Stations and OBSs information\n",
    "\n",
    "STATION_LST = ['DUB01','MAN01','CAM01','VAS01']\n",
    "\n",
    "PERIOD_BANDS2 = [0.03,0.05]\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "# create figures?\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "# Input parameters\n",
    "\n",
    "FIRSTDAY = '2017-01-01'\n",
    "LASTDAY = '2017-12-31'\n",
    "\n",
    "# default parameters to define the signal and noise windows used to estimate the SNR:\n",
    "# - the signal window is defined according to time after Rayleigh-wave arrival:\n",
    "\n",
    "# Rayleigh-wave time windows start\n",
    "TIME_START_P_REGIONAL = 40\n",
    "\n",
    "# Rayleigh-wave time windows final\n",
    "TIME_FINAL_P_REGIONAL = 800\n",
    "\n",
    "# Returns pairs and spectral SNR array whose spectral SNRs are all >= minspectSNR\n",
    "minspectSNR = 2\n",
    "\n",
    "#RESAMPLING\n",
    "NEW_SAMPLING_RATE = 1\n",
    "\n",
    "# -------------------------------\n",
    "# Mappoing parameters\n",
    "\n",
    "LLCRNRLON_LARGE = -50\n",
    "URCRNRLON_LARGE = -38\n",
    "LLCRNRLAT_LARGE = -30\n",
    "URCRNRLAT_LARGE = -12\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "# Constants and parameters\n",
    "\n",
    "ONEDAY = datetime.timedelta(days=1)\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "# MULTIPROCESSING\n",
    "\n",
    "num_processes = 20\n",
    "\n",
    "# =================\n",
    "# Filtering by date\n",
    "# =================\n",
    "\n",
    "fday = UTCDateTime(FIRSTDAY)\n",
    "lday = UTCDateTime(LASTDAY)\n",
    "INTERVAL_PERIOD = [UTCDateTime(x.astype(str)) for x in np.arange(fday.datetime,lday.datetime+ONEDAY,ONEDAY)]\n",
    "INTERVAL_PERIOD_DATE = [str(x.year)+'.'+\"%03d\" % x.julday for x in INTERVAL_PERIOD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48373d9-8612-453e-8541-b524a99126fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========\n",
    "# Functions\n",
    "# =========\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "def chael_selby_algorithm(tr1,tr2,trZ,noise,ang,dphi):\n",
    "            \n",
    "    # Rotate through and find max\n",
    "    \n",
    "    Szr = np.zeros(len(ang))\n",
    "    Rzr = np.zeros(len(ang))\n",
    "    SNR = np.zeros(len(ang))\n",
    "                            \n",
    "    for k, a in enumerate(ang):\n",
    "        R, T = rotate_ne_rt(tr1, tr2, a)\n",
    "                                \n",
    "        # Hilbert transformed radial trace data\n",
    "        trR_H = np.imag(hilbert(R))\n",
    "                \n",
    "        Czr = np.corrcoef(trZ,trR_H)[0,1]\n",
    "        Czz = np.corrcoef(trZ,trZ)[0,1]\n",
    "        Crr = np.corrcoef(trR_H,trR_H)[0,1]\n",
    "    \n",
    "        Szr[k] = Czr/Czz\n",
    "        \n",
    "        Rzr[k] = Czr/np.sqrt(np.dot(Czz,Crr))\n",
    "    \n",
    "        SNR[k] = np.abs(R).max()/noise\n",
    "                            \n",
    "    return Szr,Rzr,SNR\n",
    "\n",
    "#-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816da9d-0a59-47f2-913b-920bfea570e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============\n",
    "# Main program\n",
    "# ============\n",
    "print('==================')\n",
    "print('Downloading events')\n",
    "print('==================')\n",
    "print('\\n')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "client = Client('IRIS')\n",
    "\n",
    "cat = client.get_events(starttime=fday, endtime=lday, minmagnitude=6.5)\n",
    "print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b533b-87e8-4340-8c5b-0e559f84ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "print('============================')\n",
    "print('Calculating the orientation:')\n",
    "print('============================')\n",
    "print('\\n')\n",
    "\n",
    "SNR_MIN = 10\n",
    "CC_MIN = 0.4\n",
    "\n",
    "for sta in tqdm(STATION_LST,total=len(STATION_LST),desc='Stations'):\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Retrieving events waveforms\n",
    "    # ---------------------------\n",
    "    \n",
    "    sta_orientation = []\n",
    "    sta_Szr_max = []\n",
    "    sta_SRN = []\n",
    "    \n",
    "    for event in tqdm(cat, total=len(cat),desc=sta+' orientation'):\n",
    "        # --------------------\n",
    "        # Check if file exists\n",
    "        event_time = event.origins[-1].time\n",
    "        event_name = event.origins[-1].time.strftime('%Y.%j.%H.%M.%S')\n",
    "\n",
    "        year = event.origins[-1].time.strftime('%Y')\n",
    "        julian_day = event.origins[-1].time.strftime('%j')\n",
    "\n",
    "        network = 'ON'\n",
    "        station = sta      \n",
    "        \n",
    "        output_FEATHER_FILES_ORIENTATION = ORIENTATION_OUTPUT+'FEATHER_FILES/'+sta+'/'\n",
    "        \n",
    "        file_feather_name = output_FEATHER_FILES_ORIENTATION+event_name+'_ORIENTATION_data.feather'\n",
    "\n",
    "        station_pwd = glob.glob(EVENT_DIR+year+'/'+network+'/'+station+'/*')\n",
    "\n",
    "        if os.path.isfile(file_feather_name):\n",
    "            pass\n",
    "    \n",
    "        else:\n",
    "            \n",
    "            if (len([i for i in station_pwd if 'HHE.D' in i or 'HH1.D' in i]) > 0 and\n",
    "                len([i for i in station_pwd if 'HHN.D' in i or 'HH2.D' in i]) > 0 and\n",
    "                len([i for i in station_pwd if 'HHZ.D' in i]) > 0):\n",
    "\n",
    "                if (len(glob.glob([i for i in station_pwd if 'HHE.D' in i or 'HH1.D' in i][0]+'/*'+year+'.'+julian_day)) > 0 and\n",
    "                    len(glob.glob([i for i in station_pwd if 'HHN.D' in i or 'HH2.D' in i][0]+'/*'+year+'.'+julian_day)) > 0 and\n",
    "                    len(glob.glob([i for i in station_pwd if 'HHZ.D' in i][0]+'/*'+year+'.'+julian_day)) > 0):\n",
    "                \n",
    "                    #try:\n",
    "                    \n",
    "                        file_HHE = glob.glob([i for i in station_pwd if 'HHE.D' in i or 'HH1.D' in i][0]+'/*'+year+'.'+julian_day)[0]\n",
    "                        file_HHN = glob.glob([i for i in station_pwd if 'HHN.D' in i or 'HH2.D' in i][0]+'/*'+year+'.'+julian_day)[0]\n",
    "                        file_HHZ = glob.glob([i for i in station_pwd if 'HHZ.D' in i][0]+'/*'+year+'.'+julian_day)[0]\n",
    "    \n",
    "                        # --------\n",
    "                        # Data HHE\n",
    "                        \n",
    "                        tr2_data_file = op.read(file_HHE)\n",
    "                        tr2_data_file.trim(event_time+TIME_START_P_REGIONAL,event_time+TIME_FINAL_P_REGIONAL)\n",
    "                        tr2_data_file.decimate(factor=10, strict_length=False)\n",
    "                        tr2_data_file.taper(type='cosine',max_percentage=0.1)\n",
    "                        tr2_data_file.filter('bandpass',freqmin=PERIOD_BANDS2[0],freqmax=PERIOD_BANDS2[1],zerophase=True)\n",
    "                        tr2_data_filtered = tr2_data_file[0].data\n",
    "            \n",
    "                        # --------\n",
    "                        # Data HHN\n",
    "            \n",
    "                        tr1_data_file = op.read(file_HHN)\n",
    "                        tr1_data_file.trim(event_time+TIME_START_P_REGIONAL,event_time+TIME_FINAL_P_REGIONAL)\n",
    "                        tr1_data_file.decimate(factor=10, strict_length=False)\n",
    "                        tr1_data_file.taper(type='cosine',max_percentage=0.1)\n",
    "                        tr1_data_file.filter('bandpass',freqmin=PERIOD_BANDS2[0],freqmax=PERIOD_BANDS2[1],zerophase=True)\n",
    "                        tr1_data_filtered = tr1_data_file[0].data\n",
    "                        \n",
    "                        # --------\n",
    "                        # Data HHZ\n",
    "                        \n",
    "                        trZ_data_file = op.read(file_HHZ)\n",
    "                        trZ_data_file.trim(event_time+TIME_START_P_REGIONAL,event_time+TIME_FINAL_P_REGIONAL)\n",
    "                        trZ_data_file.decimate(factor=10, strict_length=False)\n",
    "                        trZ_data_file.taper(type='cosine',max_percentage=0.1)\n",
    "                        trZ_data_file.filter('bandpass',freqmin=PERIOD_BANDS2[0],freqmax=PERIOD_BANDS2[1],zerophase=True)\n",
    "                        trZ_data_filtered = trZ_data_file[0].data\n",
    "                        trZ_time = trZ_data_file[0].times()\n",
    "            \n",
    "                        # ---------------\n",
    "                        # Import XML file\n",
    "                        \n",
    "                        xml_file = glob.glob(XML_DIR+network+'.'+sta+'*')[0]\n",
    "                        station_xml = op.read_inventory(xml_file)\n",
    "                            \n",
    "                        # Epicentral distance:\n",
    "            \n",
    "                        sta_lon = station_xml[-1][-1][-1].longitude\n",
    "                        sta_lat = station_xml[-1][-1][-1].latitude\n",
    "            \n",
    "                        ev_lat = event.origins[-1].latitude\n",
    "                        ev_lon = event.origins[-1].longitude\n",
    "            \n",
    "                        dist_pair,az_pair,baz_pair = gps2dist_azimuth(ev_lat, ev_lon,sta_lat, sta_lon)\n",
    "                        gcarc_pair = kilometers2degrees(dist_pair/1000)\n",
    "                        gcarc_pair_round = round(gcarc_pair)\n",
    "                        dist_pair_round = round(dist_pair)\n",
    "                        \n",
    "                        #-------------------------------------------------------------------------------------------------------------------------------\n",
    "                        # Calculating Hilbert transform of vertical trace data\n",
    "                        \n",
    "                        trZ_H_data_filtered = np.imag(hilbert(trZ_data_filtered))\n",
    "                                \n",
    "                        #-------------------------------------------------------------------------------------------------------------------------------\n",
    "                        \n",
    "                        signal_window = (trZ_time >= TIME_START_P_REGIONAL) & (trZ_time <= TIME_FINAL_P_REGIONAL)\n",
    "                        noise_window = (trZ_time < TIME_START_P_REGIONAL) != (trZ_time > TIME_FINAL_P_REGIONAL)\n",
    "                        \n",
    "                        noise = tr1_data_filtered[noise_window].std()\n",
    "\n",
    "                        tr2 = tr2_data_filtered[signal_window]\n",
    "                        tr1 = tr1_data_filtered[signal_window]\n",
    "                        trZ = trZ_data_filtered[signal_window]\n",
    "                        \n",
    "                        dphi = 0.1\n",
    "                        ang = np.arange(0., 360., dphi)\n",
    "                        \n",
    "                        Szr,Rzr,SNR = chael_selby_algorithm(tr1,tr2,trZ,noise,ang,dphi)\n",
    "            \n",
    "                        # Get argument of maximum of Czr:\n",
    "                        best_index = np.argmax(Szr)                     \n",
    "                        \n",
    "                        # Get azimuth and correct for angles above 360\n",
    "                        phi = baz_pair - ang[best_index]\n",
    "                        phi = phi % 360\n",
    "                            \n",
    "                        if phi > 180:\n",
    "                            phi = 360 - phi \n",
    "                        \n",
    "                        # Get argument of maximum coherence:\n",
    "                        \n",
    "                        Szr_max = Szr[best_index]\n",
    "                        Rzr_max = Rzr[best_index]\n",
    "                        SNR_max = SNR[best_index]\n",
    "            \n",
    "                        sta_orientation.append(phi)\n",
    "                        sta_Szr_max.append(Szr_max)\n",
    "                        sta_SRN.append(SNR_max)\n",
    "            \n",
    "                        # ----------------------------------------------------------------------------------------------------\n",
    "                        # Creating a Pandas DataFrame:\n",
    "                        column_info = [sta,dist_pair,gcarc_pair,baz_pair,Szr_max,Rzr_max,SNR_max,phi]\n",
    "            \n",
    "                        columns_header = ['station','distance','gcarc','baz','Szr_max','Rzr_max','SNR_max','orient']\n",
    "            \n",
    "                        orient_rayleigh_df = pd.DataFrame(column_info, index=columns_header).T\n",
    "            \n",
    "                        # ----------------------------------------------------------------------------------------------------\n",
    "                        # Convert from pandas to Arrow and saving in feather formart file\n",
    "                        os.makedirs(output_FEATHER_FILES_ORIENTATION,exist_ok=True)\n",
    "                        feather.write_feather(orient_rayleigh_df, file_feather_name)\n",
    "                        # ----------------------------------------------------------------------------------------------------\n",
    "                        \n",
    "                        if VERBOSE == True:\n",
    "            \n",
    "                            # --------------------\n",
    "                            # fig CrossCorrelation\n",
    "                            fig = plt.figure(figsize=(20, 10))\n",
    "                            fig.suptitle('Evento: '+event_name+'\\n Δ: '+str(gcarc_pair_round)+'° | M: '+str(event.magnitudes[-1].mag)+' '+event.magnitudes[-1].magnitude_type,fontsize=20)\n",
    "            \n",
    "                            gs = gridspec.GridSpec(3, 2,wspace=0.2, hspace=0.5)\n",
    "            \n",
    "                            new_R, new_T = rotate_ne_rt(tr1_data_filtered, tr2_data_filtered, phi)\n",
    "            \n",
    "                            ax1 = fig.add_subplot(gs[0,0])\n",
    "                            ax1.plot(trZ_time,new_T,'-k')\n",
    "                            ax1.set_ylabel('HHE')\n",
    "                            ax1.set_xlabel('Timelag (s)')\n",
    "                            ax1.axvline(x=TIME_START_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "                            ax1.axvline(x=TIME_FINAL_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "            \n",
    "                            ax2 = fig.add_subplot(gs[1,0], sharey=ax1, sharex=ax1)\n",
    "                            ax2.plot(trZ_time,new_R,'-k')\n",
    "                            ax2.plot(trZ_time,trZ_H_data_filtered,'--r')\n",
    "                            ax2.set_ylabel('HHN')\n",
    "                            ax2.set_xlabel('Timelag (s)')\n",
    "                            ax2.axvline(x=TIME_START_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "                            ax2.axvline(x=TIME_FINAL_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "            \n",
    "                            ax3 = fig.add_subplot(gs[2,0], sharey=ax1, sharex=ax1)\n",
    "                            ax3.plot(trZ_time,trZ_data_filtered,'-k')\n",
    "                            ax3.set_ylabel('HHZ')\n",
    "                            ax3.set_xlabel('Timelag (s)')\n",
    "                            ax3.axvline(x=TIME_START_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "                            ax3.axvline(x=TIME_FINAL_P_REGIONAL, ymin=0, ymax=1,color='gray',linestyle='--',lw=1)\n",
    "            \n",
    "                            ax4 = fig.add_subplot(gs[0,1])\n",
    "                            ax4.plot(ang,Rzr,'.k')\n",
    "                            ax4.plot(phi,Rzr_max,'*r')\n",
    "                            ax4.set_ylabel('$R_{rz}$')\n",
    "                            ax4.set_xlabel('Orientation Angle (deg)')\n",
    "            \n",
    "                            ax5 = fig.add_subplot(gs[1,1], sharex=ax4)\n",
    "                            ax5.plot(ang,Szr,'.k')\n",
    "                            ax5.plot(phi,Szr_max,'*r')\n",
    "                            ax5.set_ylabel('$S_{rz}$')\n",
    "                            ax5.set_xlabel('Orientation Angle (deg)')\n",
    "            \n",
    "                            ax6 = fig.add_subplot(gs[2,1])\n",
    "                            ax6.plot(ang,SNR,'.k')\n",
    "                            ax6.plot(phi,SNR_max,'*r')\n",
    "                            ax6.set_ylabel('SNR')\n",
    "                            ax6.set_xlabel('Orientation Angle (deg)')\n",
    "            \n",
    "                            if (Rzr_max >= CC_MIN) & (SNR_max >= SNR_MIN):\n",
    "                                label = 'good'\n",
    "                            else:\n",
    "                                label = 'bad'\n",
    "                            output_figure_ORIENTATION = ORIENTATION_OUTPUT+'ORIENTATION_FIGURES/EARTHQUAKES/'+sta+'/'\n",
    "                            os.makedirs(output_figure_ORIENTATION,exist_ok=True)\n",
    "                            fig.savefig(output_figure_ORIENTATION+'ORIENTATION_'+event_name+'_'+label+'.png',dpi=300)\n",
    "                            plt.close()\n",
    "        \n",
    "                    #except:\n",
    "                        #pass\n",
    "    #Creating the figure\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.suptitle(sta,fontsize=20)\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 1,wspace=0.2, hspace=0.5)\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "\n",
    "    sta_orientation_np = np.array(sta_orientation)\n",
    "    sta_cc1_max_np = np.array(sta_Szr_max)\n",
    "    sta_SRN_np = np.array(sta_SRN)\n",
    "\n",
    "    th_mask = (sta_cc1_max_np >= CC_MIN) & (sta_SRN_np >= SNR_MIN)\n",
    "    th_mask_ = (sta_cc1_max_np < CC_MIN) & (sta_SRN_np < SNR_MIN)\n",
    "\n",
    "    sta_orientation_np_good = sta_orientation_np[th_mask]\n",
    "    sta_cc1_max_np_good = sta_cc1_max_np[th_mask]\n",
    "\n",
    "    sta_orientation_np_bad = sta_orientation_np[th_mask_]\n",
    "    sta_cc1_max_np_bad = sta_cc1_max_np[th_mask_]\n",
    "\n",
    "    #Simple Linear Regression With scikit-learn\n",
    "    #Provide data:\n",
    "    x = np.array(range(len(sta_cc1_max_np_good))).reshape((-1, 1))\n",
    "    y = sta_orientation_np_good\n",
    "\n",
    "    x_pred = np.arange(start=0,stop=1,step=0.1)\n",
    "\n",
    "    model = TheilSenRegressor(n_jobs=12,max_iter=500)\n",
    "    model.fit(x, y)\n",
    "    y_pred = model.predict(np.array(range(len(x_pred))).reshape((-1, 1)))\n",
    "\n",
    "    ax1.plot(sta_orientation_np_bad,sta_cc1_max_np_bad,'.k')\n",
    "    ax1.plot(sta_orientation_np_good,sta_cc1_max_np_good,'ok')\n",
    "    ax1.plot(np.mean(y_pred),np.mean(sta_cc1_max_np_good),'*r')\n",
    "\n",
    "    ax1.set_ylim(0,1)\n",
    "    ax1.set_xlim(0,360)\n",
    "    ax1.set_ylabel('$R_{rz}$')\n",
    "    ax1.set_xlabel('Orientation (degrees)')\n",
    "\n",
    "    output_figure_ORIENTATION = ORIENTATION_OUTPUT+'ORIENTATION_FIGURES/EARTHQUAKES/'+sta+'/'\n",
    "    os.makedirs(output_figure_ORIENTATION,exist_ok=True)\n",
    "    fig.savefig(output_figure_ORIENTATION+'ORIENTATION_TOTAL_'+sta+'.png',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "print('\\n')\n",
    "print(\"--- %.2f execution time (min) ---\" % ((time.time() - start_time)/60))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e43db3f-11f3-4e87-893d-07201b5ad15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41549c2d-bcaf-489d-8950-93471adb25c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
